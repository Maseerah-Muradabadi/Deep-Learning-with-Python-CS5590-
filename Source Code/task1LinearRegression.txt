import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

plt.style.use(style='ggplot')
plt.rcParams['figure.figsize'] = (10, 6)

train = pd.read_csv('train.csv')

train.SalePrice.describe()

# Next, we'll check for skewness
print("Train Skew is:", train.SalePrice.skew())
plt.hist(train.SalePrice, color='blue')
plt.show()

target = np.log(train.SalePrice)
print("Target Skew is:", target.skew())
plt.hist(target, color='blue')
plt.show()

# Working with Numeric Features
numeric_features = train.select_dtypes(include=[np.number])

corr = numeric_features.corr()

print(corr['SalePrice'].sort_values(ascending=False)[:5], '\n')
print(corr['SalePrice'].sort_values(ascending=False)[-5:])

quality_pivot = train.pivot_table(index='OverallQual', values='SalePrice', aggfunc=np.median)
#print(quality_pivot)

# Notice that the median sales price strictly increases as Overall Quality increases.
quality_pivot.plot(kind='bar', color='blue')
plt.xlabel('Overall Quality')
plt.ylabel('Median Sale Price')
plt.xticks(rotation=0)
plt.show()

# Null values
nulls = pd.DataFrame(train.isnull().sum().sort_values(ascending=False)[:25])
nulls.columns = ['Null Count']
nulls.index.name = 'Feature'
#print(nulls)

# handling missing value
data = train.select_dtypes(include=[np.number]).interpolate().dropna()
print(sum(data.isnull().sum() != 0))

##Build a linear model
y = np.log(train.SalePrice)
X = data.drop(['SalePrice', 'Id'], axis=1)
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.33)
from sklearn import linear_model

lr = linear_model.LinearRegression()
model = lr.fit(X_train, y_train)

# Evaluate the performance and visualize results
print("R^2 is: \n", model.score(X_test, y_test))
predictions = model.predict(X_test)
from sklearn.metrics import mean_squared_error

print('RMSE is: \n', mean_squared_error(y_test, predictions))

##visualize

actual_values = y_test
plt.scatter(predictions, actual_values, alpha=.75, color='b')  # alpha helps to show overlapping data
plt.xlabel('Predicted Price')
plt.ylabel('Actual Price')
plt.title('Linear Regression Model')
plt.show()

# checking anomalies in data X= Garage Area and Y = Seal Price
fig, ax = plt.subplots(figsize=(10, 6))
ax.scatter(train['GarageArea'], train['SalePrice'], ), ax.set_xlabel('GarageArea'), ax.set_ylabel('SalePrice'),
plt.show()

# removing outliers using IQR - Method 1
q1 = train.quantile(0.25)
q3 = train.quantile(0.75)
iqr = q1 - q3
train_out = train[~((train < (q1 - 1.5 * iqr)) | (train > (q3 + 1.5 * iqr))).any(axis=1)]
var = train_out.shape

# Plot graph after removing outliers from GarageArea and SalePrice - Method 2
x_outlier = train[train.GarageArea < 1200]
y_outlier = x_outlier[train.SalePrice < 500000]
fig, o = plt.subplots(figsize=(10, 6))
plt.scatter(y_outlier['GarageArea'], y_outlier['SalePrice'], alpha=.75, color='y')
plt.xlabel('GarageArea')
plt.ylabel('SalePrice')
plt.show()
